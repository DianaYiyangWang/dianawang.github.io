
@online{noauthor_phd_nodate,
	title = {Ph.D. {CS} Human-Computer Interaction Body of Knowledge {\textbar} College of Computing},
	url = {https://www.cc.gatech.edu/phd-cs-human-computer-interaction-body-knowledge},
	urldate = {2024-10-22},
	file = {Ph.D. CS Human-Computer Interaction Body of Knowledge | College of Computing:/Users/yiyangwang/Zotero/storage/AMS28H4D/phd-cs-human-computer-interaction-body-knowledge.html:text/html},
}

@book{burrell_sociological_2011,
	location = {Farnham},
	edition = {Reprinted},
	title = {Sociological paradigms and organisational analysis: elements of the sociology of corporate life},
	isbn = {978-0-566-05148-7 978-1-85742-114-9},
	shorttitle = {Sociological paradigms and organisational analysis},
	pagetotal = {432},
	publisher = {Ashgate},
	author = {Burrell, Gibson and Morgan, Gareth},
	date = {2011},
	langid = {english},
	file = {Burrell and Morgan - 2011 - Sociological paradigms and organisational analysis.pdf:/Users/yiyangwang/Zotero/storage/9L6XZUIP/Burrell and Morgan - 2011 - Sociological paradigms and organisational analysis.pdf:application/pdf},
}

@article{zhang_necksense_2020,
	title = {{NeckSense}: A Multi-Sensor Necklace for Detecting Eating Activities in Free-Living Conditions},
	volume = {4},
	url = {https://doi.org/10.1145/3397313},
	doi = {10.1145/3397313},
	shorttitle = {{NeckSense}},
	abstract = {We present the design, implementation, and evaluation of a multi-sensor, low-power necklace, {NeckSense}, for automatically and unobtrusively capturing fine-grained information about an individual's eating activity and eating episodes, across an entire waking day in a naturalistic setting. {NeckSense} fuses and classifies the proximity of the necklace from the chin, the ambient light, the Lean Forward Angle, and the energy signals to determine chewing sequences, a building block of the eating activity. It then clusters the identified chewing sequences to determine eating episodes. We tested {NeckSense} on 11 participants with and 9 participants without obesity, across two studies, where we collected more than 470 hours of data in a naturalistic setting. Our results demonstrate that {NeckSense} enables reliable eating detection for individuals with diverse body mass index ({BMI}) profiles, across an entire waking day, even in free-living environments. Overall, our system achieves an F1-score of 81.6\% in detecting eating episodes in an exploratory study. Moreover, our system can achieve an F1-score of 77.1\% for episodes even in an all-day-long free-living setting. With more than 15.8 hours of battery life, {NeckSense} will allow researchers and dietitians to better understand natural chewing and eating behaviors. In the future, researchers and dietitians can use {NeckSense} to provide appropriate real-time interventions when an eating episode is detected or when problematic eating is identified.},
	pages = {72:1--72:26},
	number = {2},
	journaltitle = {Proc. {ACM} Interact. Mob. Wearable Ubiquitous Technol.},
	author = {Zhang, Shibo and Zhao, Yuqi and Nguyen, Dzung Tri and Xu, Runsheng and Sen, Sougata and Hester, Josiah and Alshurafa, Nabil},
	urldate = {2024-11-12},
	date = {2020-06-15},
	file = {Accepted Version:/Users/yiyangwang/Zotero/storage/976DRC5Z/Zhang et al. - 2020 - NeckSense A Multi-Sensor Necklace for Detecting E.pdf:application/pdf},
}

@online{noauthor_detecting_nodate,
	title = {Detecting Eating, and Social Presence with All Day Wearable {RGB}-T {\textbar} Proceedings of the 8th {ACM}/{IEEE} International Conference on Connected Health: Applications, Systems and Engineering Technologies},
	url = {https://dl.acm.org/doi/abs/10.1145/3580252.3586974},
	urldate = {2024-11-12},
}

@article{alshurafa_rationale_2023,
	title = {Rationale and design of the {SenseWhy} project: A passive sensing and ecological momentary assessment study on characteristics of overeating episodes},
	volume = {9},
	issn = {2055-2076},
	url = {https://doi.org/10.1177/20552076231158314},
	doi = {10.1177/20552076231158314},
	shorttitle = {Rationale and design of the {SenseWhy} project},
	abstract = {{ObjectivesOvereating} interventions and research often focus on single determinants and use subjective or nonpersonalized measures. We aim to (1) identify automatically detectable features that predict overeating and (2) build clusters of eating episodes that identify theoretically meaningful and clinically known problematic overeating behaviors (e.g., stress eating), as well as new phenotypes based on social and psychological features.{MethodUp} to 60 adults with obesity in the Chicagoland area will be recruited for a 14-day free-living observational study. Participants will complete ecological momentary assessments and wear 3 sensors designed to capture features of overeating episodes (e.g., chews) that can be visually confirmed. Participants will also complete daily dietitian-administered 24-hour recalls of all food and beverages consumed.{AnalysisOvereating} is defined as caloric consumption exceeding 1 standard deviation of an individual's mean consumption per eating episode. To identify features that predict overeating, we will apply 2 complementary machine learning methods: correlation-based feature selection and wrapper-based feature selection. We will then generate clusters of overeating types and assess how they align with clinically meaningful overeating phenotypes.{ConclusionsThis} study will be the first to assess characteristics of eating episodes in situ over a multiweek period with visual confirmation of eating behaviors. An additional strength of this study is the assessment of predictors of problematic eating during periods when individuals are not on a structured diet and/or engaged in a weight loss intervention. Our assessment of overeating episodes in real-world settings is likely to yield new insights regarding determinants of overeating that may translate into novel interventions.},
	pages = {20552076231158314},
	journaltitle = {{DIGITAL} {HEALTH}},
	author = {Alshurafa, Nabil I. and Stump, Tammy K. and Romano, Christopher S. and F. Pfammatter, Angela and Lin, Annie W. and Hester, Josiah and Hedeker, Donald and Forman, Evan and Spring, Bonnie},
	urldate = {2024-11-12},
	date = {2023-01-01},
	langid = {english},
	note = {Publisher: {SAGE} Publications Ltd},
	file = {SAGE PDF Full Text:/Users/yiyangwang/Zotero/storage/TV5265UA/Alshurafa et al. - 2023 - Rationale and design of the SenseWhy project A pa.pdf:application/pdf},
}

@inproceedings{cruz_equityware_2023,
	location = {New York, {NY}, {USA}},
	title = {{EquityWare}: Co-Designing Wearables With And For Low Income Communities In The U.S.},
	isbn = {978-1-4503-9421-5},
	url = {https://dl.acm.org/doi/10.1145/3544548.3580980},
	doi = {10.1145/3544548.3580980},
	series = {{CHI} '23},
	shorttitle = {{EquityWare}},
	abstract = {Wearables are a potentially vital mechanism for individuals to monitor their health, track behaviors, and stay connected. Unfortunately, both price and a lack of consideration of the needs of low-{SES} communities have made these devices inaccessible and unusable for communities that would most substantially benefit from their affordances. To address this gap and better understand how members of low-{SES} communities perceive the potential benefits and barriers to using wearable devices, we conducted 19 semi-structured interviews with people from minority, high crime rate, low-{SES} communities. Participants emphasized a critical need for safety-related wearable devices in their communities. Still, existing tools do not yet address the specific needs of this community and are out of reach due to several barriers. We distill themes on perceived useful features and ongoing obstacles to guide a much-needed research agenda we term ’Equityware’: building wearable devices based on low-{SES} communities’ needs, comfortability, and limitations.},
	pages = {1--18},
	booktitle = {Proceedings of the 2023 {CHI} Conference on Human Factors in Computing Systems},
	publisher = {Association for Computing Machinery},
	author = {Cruz, Stefany and Redding, Alexander and Chau, Connie W. and Lu, Claire and Persche, Julia and Hester, Josiah and Jacobs, Maia},
	urldate = {2024-11-12},
	date = {2023-04-19},
	file = {Full Text PDF:/Users/yiyangwang/Zotero/storage/88WY6IMW/Cruz et al. - 2023 - EquityWare Co-Designing Wearables With And For Lo.pdf:application/pdf},
}

@online{noauthor_estimation_nodate,
	title = {Estimation of Changes in Intracardiac Hemodynamics Using Wearable Seismocardiography and Machine Learning in Patients With Heart Failure: A Feasibility Study {\textbar} {IEEE} Journals \& Magazine {\textbar} {IEEE} Xplore},
	url = {https://ieeexplore.ieee.org/document/9697365},
	urldate = {2024-11-12},
}

@article{quesada_use_2021,
	title = {Use of Ballistocardiography to Monitor Cardiovascular Hemodynamics in Preeclampsia},
	volume = {2},
	url = {https://pmc.ncbi.nlm.nih.gov/articles/PMC8080913/},
	doi = {10.1089/whr.2020.0127},
	abstract = {Objective: Pregnancy requires a complex physiological adaptation of the maternal cardiovascular system, which is disrupted in women with pregnancies complicated by preeclampsia, putting them at higher risk of future cardiovascular events. The ...},
	pages = {97},
	number = {1},
	journaltitle = {Women's Health Reports},
	author = {Quesada, Odayme and Shandhi, Md Mobashir Hasan and Beach, Shire and Dowling, Sean and Tandon, Damini and Heller, James and Etemadi, Mozziyar and Roy, Shuvo and Velez, Juan M. Gonzalez and Inan, Omer T. and Klein, Liviu},
	urldate = {2024-11-12},
	date = {2021-04-20},
	langid = {english},
	pmid = {33937907},
	file = {Full Text PDF:/Users/yiyangwang/Zotero/storage/SQPRLECA/Quesada et al. - 2021 - Use of Ballistocardiography to Monitor Cardiovascu.pdf:application/pdf},
}

@article{fernandes_habitsense_2024,
	title = {{HabitSense}: A Privacy-Aware, {AI}-Enhanced Multimodal Wearable Platform for {mHealth} Applications},
	volume = {8},
	url = {https://doi.org/10.1145/3678591},
	doi = {10.1145/3678591},
	shorttitle = {{HabitSense}},
	abstract = {Wearable cameras provide an objective method to visually confirm and automate the detection of health-risk behaviors such as smoking and overeating, which is critical for developing and testing adaptive treatment interventions. Despite the potential of wearable camera systems, adoption is hindered by inadequate clinician input in the design, user privacy concerns, and user burden. To address these barriers, we introduced {HabitSense}, an open-source1, multi-modal neck-worn platform developed with input from focus groups with clinicians (N=36) and user feedback from in-wild studies involving 105 participants over 35 days. Optimized for monitoring health-risk behaviors, the platform utilizes {RGB}, thermal, and inertial measurement unit sensors to detect eating and smoking events in real time. In a 7-day study involving 15 participants, {HabitSense} recorded 768 hours of footage, capturing 420.91 minutes of hand-to-mouth gestures associated with eating and smoking data crucial for training machine learning models, achieving a 92\% F1-score in gesture recognition. To address privacy concerns, the platform records only during likely health-risk behavior events using {SECURE}, a smart activation algorithm. Additionally, {HabitSense} employs on-device obfuscation algorithms that selectively obfuscate the background during recording, maintaining individual privacy while leaving gestures related to health-risk behaviors unobfuscated. Our implementation of {SECURE} has resulted in a 48\% reduction in storage needs and a 30\% increase in battery life. This paper highlights the critical roles of clinician feedback, extensive field testing, and privacy-enhancing algorithms in developing an unobtrusive, lightweight, and reproducible wearable system that is both feasible and acceptable for monitoring health-risk behaviors in real-world settings.},
	pages = {101:1--101:48},
	number = {3},
	journaltitle = {Proc. {ACM} Interact. Mob. Wearable Ubiquitous Technol.},
	author = {Fernandes, Glenn J. and Zheng, Jiayi and Pedram, Mahdi and Romano, Christopher and Shahabi, Farzad and Rothrock, Blaine and Cohen, Thomas and Zhu, Helen and Butani, Tanmeet S. and Hester, Josiah and Katsaggelos, Aggelos K. and Alshurafa, Nabil},
	urldate = {2024-11-12},
	date = {2024-09-09},
}

@inproceedings{cruz_equityware_2023-1,
	location = {New York, {NY}, {USA}},
	title = {{EquityWare}: Co-Designing Wearables With And For Low Income Communities In The U.S.},
	isbn = {978-1-4503-9421-5},
	url = {https://dl.acm.org/doi/10.1145/3544548.3580980},
	doi = {10.1145/3544548.3580980},
	series = {{CHI} '23},
	shorttitle = {{EquityWare}},
	abstract = {Wearables are a potentially vital mechanism for individuals to monitor their health, track behaviors, and stay connected. Unfortunately, both price and a lack of consideration of the needs of low-{SES} communities have made these devices inaccessible and unusable for communities that would most substantially benefit from their affordances. To address this gap and better understand how members of low-{SES} communities perceive the potential benefits and barriers to using wearable devices, we conducted 19 semi-structured interviews with people from minority, high crime rate, low-{SES} communities. Participants emphasized a critical need for safety-related wearable devices in their communities. Still, existing tools do not yet address the specific needs of this community and are out of reach due to several barriers. We distill themes on perceived useful features and ongoing obstacles to guide a much-needed research agenda we term ’Equityware’: building wearable devices based on low-{SES} communities’ needs, comfortability, and limitations.},
	pages = {1--18},
	booktitle = {Proceedings of the 2023 {CHI} Conference on Human Factors in Computing Systems},
	publisher = {Association for Computing Machinery},
	author = {Cruz, Stefany and Redding, Alexander and Chau, Connie W. and Lu, Claire and Persche, Julia and Hester, Josiah and Jacobs, Maia},
	urldate = {2024-11-12},
	date = {2023-04-19},
	file = {Full Text PDF:/Users/yiyangwang/Zotero/storage/9JCXV3VN/Cruz et al. - 2023 - EquityWare Co-Designing Wearables With And For Lo.pdf:application/pdf},
}

@article{ganti_enabling_2021,
	title = {Enabling Wearable Pulse Transit Time-Based Blood Pressure Estimation for Medically Underserved Areas and Health Equity: Comprehensive Evaluation Study},
	volume = {9},
	issn = {2291-5222},
	doi = {10.2196/27466},
	shorttitle = {Enabling Wearable Pulse Transit Time-Based Blood Pressure Estimation for Medically Underserved Areas and Health Equity},
	abstract = {{BACKGROUND}: Noninvasive and cuffless approaches to monitor blood pressure ({BP}), in light of their convenience and accuracy, have paved the way toward remote screening and management of hypertension. However, existing noninvasive methodologies, which operate on mechanical, electrical, and optical sensing modalities, have not been thoroughly evaluated in demographically and racially diverse populations. Thus, the potential accuracy of these technologies in populations where they could have the greatest impact has not been sufficiently addressed. This presents challenges in clinical translation due to concerns about perpetuating existing health disparities.
{OBJECTIVE}: In this paper, we aim to present findings on the feasibility of a cuffless, wrist-worn, pulse transit time ({PTT})-based device for monitoring {BP} in a diverse population.
{METHODS}: We recruited a diverse population through a collaborative effort with a nonprofit organization working with medically underserved areas in Georgia. We used our custom, multimodal, wrist-worn device to measure the {PTT} through seismocardiography, as the proximal timing reference, and photoplethysmography, as the distal timing reference. In addition, we created a novel data-driven beat-selection algorithm to reduce noise and improve the robustness of the method. We compared the wearable {PTT} measurements with those from a finger-cuff continuous {BP} device over the course of several perturbations used to modulate {BP}.
{RESULTS}: Our {PTT}-based wrist-worn device accurately monitored diastolic blood pressure ({DBP}) and mean arterial pressure ({MAP}) in a diverse population (N=44 participants) with a mean absolute difference of 2.90 mm Hg and 3.39 mm Hg for {DBP} and {MAP}, respectively, after calibration. Meanwhile, the mean absolute difference of our systolic {BP} estimation was 5.36 mm Hg, a grade B classification based on the Institute for Electronics and Electrical Engineers standard. We have further demonstrated the ability of our device to capture the commonly observed demographic differences in underlying arterial stiffness.
{CONCLUSIONS}: Accurate {DBP} and {MAP} estimation, along with grade B systolic {BP} estimation, using a convenient wearable device can empower users and facilitate remote {BP} monitoring in medically underserved areas, thus providing widespread hypertension screening and management for health equity.},
	pages = {e27466},
	number = {8},
	journaltitle = {{JMIR} {mHealth} and {uHealth}},
	shortjournal = {{JMIR} Mhealth Uhealth},
	author = {Ganti, Venu and Carek, Andrew M. and Jung, Hewon and Srivatsa, Adith V. and Cherry, Deborah and Johnson, Levather Neicey and Inan, Omer T.},
	date = {2021-08-02},
	pmid = {34338646},
	pmcid = {PMC8369375},
	keywords = {Humans, Blood Pressure, cuffless blood pressure, health equity, Health Equity, Medically Underserved Area, mobile phone, noninvasive blood pressure estimation, pulse transit time, Pulse Wave Analysis, Wearable Electronic Devices, wearable sensing},
	file = {Full Text:/Users/yiyangwang/Zotero/storage/EYZJ5UUH/Ganti et al. - 2021 - Enabling Wearable Pulse Transit Time-Based Blood P.pdf:application/pdf},
}

@online{noauthor_functionality_nodate,
	title = {Functionality and User Review Analysis of Mobile Apps for Mindfulness Eating and Eating Disorders {\textbar} Proceedings of the 2024 {ACM} Designing Interactive Systems Conference},
	url = {https://dl.acm.org/doi/10.1145/3643834.3661521},
	urldate = {2024-11-18},
	file = {Functionality and User Review Analysis of Mobile Apps for Mindfulness Eating and Eating Disorders | Proceedings of the 2024 ACM Designing Interactive Systems Conference:/Users/yiyangwang/Zotero/storage/KUPMRBLW/3643834.html:text/html},
}

@inproceedings{guluzade_functionality_2024,
	location = {New York, {NY}, {USA}},
	title = {Functionality and User Review Analysis of Mobile Apps for Mindfulness Eating and Eating Disorders},
	isbn = {9798400705830},
	url = {https://dl.acm.org/doi/10.1145/3643834.3661521},
	doi = {10.1145/3643834.3661521},
	series = {{DIS} '24},
	abstract = {A growing number of mobile apps have focused on healthy or problematic eating, albeit limited research has focused on evaluating such apps from users’ perspectives. To address this, we evaluated the functionalities of 27 apps on mindfulness eating, and eating disorders from the Apple App, and Google Play Stores, and conducted a content analysis of 1248 user reviews, totaling over 60,000 words. Findings indicate the main functionalities of tracking data on eating behaviors, emotions, thoughts, bodily sensations, symptoms, as well as triggers of eating disorders, and of providing interventions such as mindfulness, goal setting, psychoeducation, {CBT}, and holistic ones. Findings also highlight key usability and ethical challenges, which we used to inform five design implications namely tracking and reflecting on multiple aspects of mindfulness and healthy eating, supporting personalized interventions and {AI}-based ones, as well as the sensitive design for diagnosis, and for tracking and monitoring problematic data.},
	pages = {1350--1371},
	booktitle = {Proceedings of the 2024 {ACM} Designing Interactive Systems Conference},
	publisher = {Association for Computing Machinery},
	author = {Guluzade, Lala and Sas, Corina},
	urldate = {2024-11-18},
	date = {2024-07-01},
	file = {Full Text PDF:/Users/yiyangwang/Zotero/storage/336NNIRR/Guluzade and Sas - 2024 - Functionality and User Review Analysis of Mobile A.pdf:application/pdf},
}

@inproceedings{zhang_short_2023,
	location = {Orlando {FL} {USA}},
	title = {Short: Real-Time Bladder Monitoring by Bio-impedance Analysis to Aid Urinary Incontinence},
	isbn = {9798400701023},
	url = {https://dl.acm.org/doi/10.1145/3580252.3586985},
	doi = {10.1145/3580252.3586985},
	shorttitle = {Short},
	eventtitle = {{CHASE} '23: 8th {ACM}/{IEEE} International Conference on Connected Health: Applications, Systems and Engineering Technologies},
	pages = {138--142},
	booktitle = {Proceedings of the 8th {ACM}/{IEEE} International Conference on Connected Health: Applications, Systems and Engineering Technologies},
	publisher = {{ACM}},
	author = {Zhang, Ruoyu and Fang, Ruijie and Zhang, Zhichao and Hosseini, Elahe and Orooji, Mahdi and Homayoun, Houman and Goncu-Berk, Gozde},
	urldate = {2024-11-22},
	date = {2023-06-21},
	langid = {english},
	file = {Full Text:/Users/yiyangwang/Zotero/storage/IW9B2AVC/Zhang et al. - 2023 - Short Real-Time Bladder Monitoring by Bio-impedan.pdf:application/pdf},
}

@article{brooke_sus_nodate,
	title = {{SUS} - A quick and dirty usability scale},
	abstract = {Usability does not exist in any absolute sense; it can only be defined with reference to particular contexts. This, in turn, means that there are no absolute measures of usability, since, if the usability of an artefact is defined by the context in which that artefact is used, measures of usability must of necessity be defined by that context too. Despite this, there is a need for broad general measures which can be used to compare usability across a range of contexts. In addition, there is a need for “quick and dirty” methods to allow low cost assessments of usability in industrial systems evaluation. This chapter describes the System Usability Scale ({SUS}) a reliable, low-cost usability scale that can be used for global assessments of systems usability.},
	author = {Brooke, John},
	langid = {english},
	file = {Brooke - SUS - A quick and dirty usability scale.pdf:/Users/yiyangwang/Zotero/storage/3RMMKXV3/Brooke - SUS - A quick and dirty usability scale.pdf:application/pdf},
}

@article{guo_lx2343_2017,
	title = {{LX}2343 alleviates cognitive impairments in {AD} model rats by inhibiting oxidative stress-induced neuronal apoptosis and tauopathy},
	volume = {38},
	rights = {2017 {CPS} and {SIMM}},
	issn = {1745-7254},
	url = {https://www.nature.com/articles/aps2016128},
	doi = {10.1038/aps.2016.128},
	abstract = {Alzheimer's disease ({AD}) is a progressive neurodegenerative disease leading to the irreversible loss of brain neurons and cognitive abilities, and the vicious interplay between oxidative stress ({OS}) and tauopathy is believed to be one of the major players in {AD} development. Here, we demonstrated the capability of the small molecule N-(1,3-benzodioxol-5-yl)-2-[5-chloro-2-methoxy(phenylsulfonyl)anilino]acetamide ({LX}2343) to ameliorate the cognitive dysfunction of {AD} model rats by inhibiting {OS}-induced neuronal apoptosis and tauopathy. Streptozotocin ({STZ}) was used to induce {OS} in neuronal cells in vitro and in {AD} model rats that were made by intracerebroventricular injection of {STZ} (3 mg/kg, bilaterally), and Morris water maze test was used to evaluate the cognitive dysfunction in {ICV}-{STZ} rats. Treatment with {LX}2343 (5–20 μmol/L) significantly attenuated {STZ}-induced apoptosis in {SH}-{SY}5Y cells and mouse primary cortical neurons by alleviating {OS} and inhibiting the {JNK}/p38 and pro-apoptotic pathways. {LX}2343 was able to restore the integrity of mitochondrial function and morphology, increase {ATP} biosynthesis, and reduce {ROS} accumulation in the neuronal cells. In addition, {LX}2343 was found to be a non-{ATP} competitive {GSK}-3β inhibitor with {IC}50 of 1.84±0.07 μmol/L, and it potently inhibited tau hyperphosphorylation in the neuronal cells. In {ICV}-{STZ} rats, administration of {LX}2343 (7, 21 mg·kg−1·d−1, ip, for 5 weeks) efficiently improved their cognitive deficits. {LX}2343 ameliorates the cognitive dysfunction in the {AD} model rats by suppressing {OS}-induced neuronal apoptosis and tauopathy, thus highlighting the potential of {LX}2343 for the treatment of {AD}.},
	pages = {1104--1119},
	number = {8},
	journaltitle = {Acta Pharmacologica Sinica},
	shortjournal = {Acta Pharmacol Sin},
	author = {Guo, Xiao-dan and Sun, Guang-long and Zhou, Ting-ting and Wang, Yi-yang and Xu, Xin and Shi, Xiao-fan and Zhu, Zhi-yuan and Rukachaisirikul, Vatcharin and Hu, Li-hong and Shen, Xu},
	urldate = {2024-12-30},
	date = {2017-08},
	langid = {english},
	note = {Publisher: Nature Publishing Group},
	keywords = {Biomedicine, general, Immunology, Internal Medicine, Medical Microbiology, Pharmacology/Toxicology, Vaccine},
	file = {Full Text PDF:/Users/yiyangwang/Zotero/storage/8UE6U89G/Guo et al. - 2017 - LX2343 alleviates cognitive impairments in AD mode.pdf:application/pdf},
}

@article{zhang_flexible_2022,
	title = {Flexible computational photodetectors for self-powered activity sensing},
	volume = {6},
	rights = {2022 The Author(s)},
	issn = {2397-4621},
	url = {https://www.nature.com/articles/s41528-022-00137-z},
	doi = {10.1038/s41528-022-00137-z},
	abstract = {Conventional vision-based systems, such as cameras, have demonstrated their enormous versatility in sensing human activities and developing interactive environments. However, these systems have long been criticized for incurring privacy, power, and latency issues due to their underlying structure of pixel-wise analog signal acquisition, computation, and communication. In this research, we overcome these limitations by introducing in-sensor analog computation through the distribution of interconnected photodetectors in space, having a weighted responsivity, to create what we call a computational photodetector. Computational photodetectors can be used to extract mid-level vision features as a single continuous analog signal measured via a two-pin connection. We develop computational photodetectors using thin and flexible low-noise organic photodiode arrays coupled with a self-powered wireless system to demonstrate a set of designs that capture position, orientation, direction, speed, and identification information, in a range of applications from explicit interactions on everyday surfaces to implicit activity detection.},
	pages = {1--8},
	number = {1},
	journaltitle = {npj Flexible Electronics},
	shortjournal = {npj Flex Electron},
	author = {Zhang, Dingtian and Fuentes-Hernandez, Canek and Vijayan, Raaghesh and Zhang, Yang and Li, Yunzhi and Park, Jung Wook and Wang, Yiyang and Zhao, Yuhui and Arora, Nivedita and Mirzazadeh, Ali and Do, Youngwook and Cheng, Tingyu and Swaminathan, Saiganesh and Starner, Thad and Andrew, Trisha L. and Abowd, Gregory D.},
	urldate = {2024-12-30},
	date = {2022-01-27},
	langid = {english},
	note = {Publisher: Nature Publishing Group},
	keywords = {Electrical and electronic engineering, Sensors},
	file = {Full Text PDF:/Users/yiyangwang/Zotero/storage/S6UZUEWH/Zhang et al. - 2022 - Flexible computational photodetectors for self-pow.pdf:application/pdf},
}

@article{goel_phantom_nodate,
	title = {Phantom Puffs: A Phantom Lung to Emulate Smoking Behavior},
	volume = {3},
	abstract = {Testing sensors on human subjects is fraught with challenges such as extensive setup times and inconsistent data collection. This study explores the use of phantom organs as a solution to streamline sensor testing and validation. By replicating essential organ functions, phantom organs can provide a consistent and repeatable testing environment, improving data accuracy and reliability. Our development of a phantom lung, capable of emulating human breathing patterns, exemplifies this approach. This phantom lung could facilitate the testing of {ENDS} monitoring sensors, allowing for the safe and controlled simulation of smoking combustible and electronic cigarettes. The use of phantom organs not only reduces reliance on human subjects in sensor development but also fosters innovation by allowing experimentation with novel sensing mechanisms. This research highlights the potential of phantom organs to revolutionize sensor testing practices, ultimately accelerating the advancement of sensing technologies in various fields.},
	number = {2},
	journaltitle = {Online Journal of Robotics \& Automation Technology},
	author = {Goel, Rishabh and Wang, Yiyang and Adams, Alexander T},
	langid = {english},
	note = {Publisher: Iris Publishers},
	file = {Goel et al. - Phantom Puffs A Phantom Lung to Emulate Smoking B.pdf:/Users/yiyangwang/Zotero/storage/T977HV7Y/Goel et al. - Phantom Puffs A Phantom Lung to Emulate Smoking B.pdf:application/pdf},
}

@article{zhang_optosense_2020,
	title = {{OptoSense}: Towards Ubiquitous Self-Powered Ambient Light Sensing Surfaces},
	volume = {4},
	issn = {2474-9567},
	url = {https://dl.acm.org/doi/10.1145/3411826},
	doi = {10.1145/3411826},
	shorttitle = {{OptoSense}},
	abstract = {Ubiquitous computing requires robust and sustainable sensing techniques to detect users for explicit and implicit inputs. Existing solutions with cameras can be privacy-invasive. Battery-powered sensors require user maintenance, preventing practical ubiquitous sensor deployment. We present {OptoSense}, a general-purpose self-powered sensing system which senses ambient light at the surface level of everyday objects as a high-fidelity signal to infer user activities and interactions. To situate the novelty of {OptoSense} among prior work and highlight the generalizability of the approach, we propose a design framework of ambient light sensing surfaces, enabling implicit activity sensing and explicit interactions in a wide range of use cases with varying sensing dimensions (0D, 1D, 2D), fields of view (wide, narrow), and perspectives (egocentric, allocentric). {OptoSense} supports this framework through example applications ranging from object use and indoor traffic detection, to liquid sensing and multitouch input. Additionally, the system can achieve high detection accuracy while being self-powered by ambient light. On-going improvements that replace Optosense's silicon-based sensors with organic semiconductors ({OSCs}) enable devices that are ultra-thin, flexible, and cost effective to scale.},
	pages = {1--27},
	number = {3},
	journaltitle = {Proceedings of the {ACM} on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	shortjournal = {Proc. {ACM} Interact. Mob. Wearable Ubiquitous Technol.},
	author = {Zhang, Dingtian and Park, Jung Wook and Zhang, Yang and Zhao, Yuhui and Wang, Yiyang and Li, Yunzhi and Bhagwat, Tanvi and Chou, Wen-Fang and Jia, Xiaojia and Kippelen, Bernard and Fuentes-Hernandez, Canek and Starner, Thad and Abowd, Gregory D.},
	urldate = {2024-12-30},
	date = {2020-09-04},
	langid = {english},
	file = {Zhang et al. - 2020 - OptoSense Towards Ubiquitous Self-Powered Ambient.pdf:/Users/yiyangwang/Zotero/storage/F85BIYJX/Zhang et al. - 2020 - OptoSense Towards Ubiquitous Self-Powered Ambient.pdf:application/pdf},
}

@inproceedings{jin_agentreview_2024,
	location = {Miami, Florida, {USA}},
	title = {{AgentReview}: Exploring Peer Review Dynamics with {LLM} Agents},
	url = {https://aclanthology.org/2024.emnlp-main.70},
	doi = {10.18653/v1/2024.emnlp-main.70},
	shorttitle = {{AgentReview}},
	abstract = {Peer review is fundamental to the integrity and advancement of scientific publication. Traditional methods of peer review analyses often rely on exploration and statistics of existing peer review data, which do not adequately address the multivariate nature of the process, account for the latent variables, and are further constrained by privacy concerns due to the sensitive nature of the data. We introduce {AgentReview}, the first large language model ({LLM}) based peer review simulation framework, which effectively disentangles the impacts of multiple latent factors and addresses the privacy issue. Our study reveals significant insights, including a notable 37.1\% variation in paper decisions due to reviewers' biases, supported by sociological theories such as the social influence theory, altruism fatigue, and authority bias. We believe that this study could offer valuable insights to improve the design of peer review mechanisms.},
	eventtitle = {{EMNLP} 2024},
	pages = {1208--1226},
	booktitle = {Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing},
	publisher = {Association for Computational Linguistics},
	author = {Jin, Yiqiao and Zhao, Qinlin and Wang, Yiyang and Chen, Hao and Zhu, Kaijie and Xiao, Yijia and Wang, Jindong},
	editor = {Al-Onaizan, Yaser and Bansal, Mohit and Chen, Yun-Nung},
	urldate = {2024-12-30},
	date = {2024-11},
	file = {Jin et al. - 2024 - AgentReview Exploring Peer Review Dynamics with L.pdf:/Users/yiyangwang/Zotero/storage/DK79ELVK/Jin et al. - 2024 - AgentReview Exploring Peer Review Dynamics with L.pdf:application/pdf},
}

@misc{jin_scito2m_2024,
	title = {Scito2M: A 2 Million, 30-Year Cross-disciplinary Dataset for Temporal Scientometric Analysis},
	url = {http://arxiv.org/abs/2410.09510},
	doi = {10.48550/arXiv.2410.09510},
	shorttitle = {Scito2M},
	abstract = {Understanding the creation, evolution, and dissemination of scientific knowledge is crucial for bridging diverse subject areas and addressing complex global challenges such as pandemics, climate change, and ethical {AI}. Scientometrics, the quantitative and qualitative study of scientific literature, provides valuable insights into these processes. We introduce Scito2M, a longitudinal scientometric dataset with over two million academic publications, providing comprehensive contents information and citation graphs to support cross-disciplinary analyses. Using Scito2M, we conduct a temporal study spanning over 30 years to explore key questions in scientometrics: the evolution of academic terminology, citation patterns, and interdisciplinary knowledge exchange. Our findings reveal critical insights, such as disparities in epistemic cultures, knowledge production modes, and citation practices. For example, rapidly developing, application-driven fields like {LLMs} exhibit significantly shorter citation age (2.48 years) compared to traditional theoretical disciplines like oral history (9.71 years).},
	number = {{arXiv}:2410.09510},
	publisher = {{arXiv}},
	author = {Jin, Yiqiao and Xiao, Yijia and Wang, Yiyang and Wang, Jindong},
	urldate = {2024-12-30},
	date = {2024-10-12},
	eprinttype = {arxiv},
	eprint = {2410.09510 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Digital Libraries},
}
